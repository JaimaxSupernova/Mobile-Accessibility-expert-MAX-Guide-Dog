##README.md ##Written by Marley Hayward
## Mobile Accessibility expert (MAX) Guide Dog

A GitLab repository for all documentation, code, testing notes and progress made on the development of Team 18's project in Module CE201.


## Badges

![Raspberry Pi](https://img.shields.io/badge/-RaspberryPi-C51A4A?style=for-the-badge&logo=Raspberry-Pi)
![Arduino](https://img.shields.io/badge/-Arduino-00979D?style=for-the-badge&logo=Arduino&logoColor=white)
![GitLab](https://img.shields.io/badge/gitlab-%23181717.svg?style=for-the-badge&logo=gitlab&logoColor=white)
![Jira](https://img.shields.io/badge/jira-%230A0FFF.svg?style=for-the-badge&logo=jira&logoColor=white)

## Visuals
<img src="/Users/marley/Library/Mobile Documents/com~apple~CloudDocs/Documents/University Work - iCloud/Year 2/CE201 - Team Project Challenge/gits/23-24_CE201-col_team-18/MAX Markdown Image.png" alt="MAX Product Image" style="height: 100px; width:100px;"/>

## Installation


## Usage
This device is intended to be used by people with mild to severe visual impairments. The product is intended to be a direct replacement and even upgrade of the standard guide dogs which have been used since 1931.

To use the device, place it on a level surface and use the switch on the rear of the device to turn it on. The device will enter a startup mode where the wheels of the device will allign. Once 5 seconds has passed, the device is ready for use. To prepare the device for navigation, use the device to input specific GPS co-ordinates or use an external 3rd party service like Google Maps or Apple Maps for iOS devices. Once a location has been specified, the device will calculate the quickest and most accessible route to the destnation.

The user will control and hold on to the device via a handle that mimics how a lead would be used on a typical guide dog. From this handle attatchment, the user can control the devices' speed as well as recieve feedback about their surroundings via the integrated vibration feedback. For example, if the user is approaching an object or if a hazard appears before the device and is too close, the handle will vibrate.

## Support
For support with the device, please contact the project team at:

~ Ane Jensen - aj22608@essex.ac.uk
~ Thakshon Anantharaja - ta22212@essex.ac.uk
~ Shelton Darvin - sd22310@essex.ac.uk
~ Jaimin Dave - jd22276@essex.ac.uk
~ Lavaya Annathurai - la22205@essex.ac.uk
~ Marley Hayward - mh22512@essex.ac.uk

## Roadmap
Our plans with this project start small but with the continual development could be world changing and improve missions of lives accross the world.

Our plans are as follows...

1) Build a small prototype for basic testing including navigation and hazard/object detection.
2) Create a finalized version complete with all features.
3) Manufacture the device and perform user testing with a small test group to make further improvements to the device.
4) Create the final version of the device - MAX 1.0
5) Mass produce the device and help people with visual impairmnet.


## Contributing
Currently, only students at the University of Essex taking CE201 Module and who are in Lab 10, Team 18 are contributing to the project.

If you have any feedback or ideas for MAX, please email us or post an issue in our GitLab repository.	

## Authors and acknowledgment
Team 18 Members

~ Ane Jensen - Mechatronics ,Lead 3D Modeler.

~ Thakshon Anantharaja - Robotics

~ Shelton Darvin - Mechatronics

~ Jaimin Dave - Mechatronics

~ Lavaya Annathurai - Computer Systems

~ Marley Hayward - Computer Networks, Programming 
